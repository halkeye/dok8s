---
serviceAccounts:
  server:
    create: true
    annotations: {}

alertmanager:
  strategy:
    type: Recreate
  persistentVolume:
    storageClass: do-block-storage
  baseURL: https://prometheus-alertmanager.taildba47.ts.net/
  #service:
  #  annotations:
  #    tailscale.com/expose: "true"
  ingress:
    enabled: true
    className: "tailscale"
    hosts:
      - host: prometheus-alertmanager.taildba47.ts.net
        paths:
          - path: /
            pathType: ImplementationSpecific
    tls:
      - hosts:
          - prometheus-alertmanager.taildba47.ts.net
    annotations:
      nginx.ingress.kubernetes.io/force-ssl-redirect: "true"
      nginx.ingress.kubernetes.io/proxy-body-size: "0"

server:
  baseURL: https://prometheus.taildba47.ts.net/
  strategy:
    type: Recreate
  persistentVolume:
    storageClass: do-block-storage
  #service:
  #  annotations:
  #    tailscale.com/expose: "true"
  ingress:
    enabled: true
    ingressClassName: "tailscale"
    hosts:
      - prometheus-server.taildba47.ts.net
    annotations:
      nginx.ingress.kubernetes.io/force-ssl-redirect: "true"
      nginx.ingress.kubernetes.io/proxy-body-size: "0"
    tls:
      - hosts:
          - prometheus-server.taildba47.ts.net

kube-state-metrics:
  enabled: true

serverFiles:
  alerting_rules.yml:
    groups:
      - name: Instances
        rules:
          - alert: PrometheusJobMissing
            expr: absent(up{job="prometheus"})
            for: 0m
            labels:
              severity: warning
            annotations:
              summary: Prometheus job missing (instance {{ $labels.instance }})
              description: "A Prometheus job has disappeared\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"
          - alert: PrometheusTargetMissing
            expr: up == 0
            for: 15m
            labels:
              severity: critical
            annotations:
              summary: Prometheus target missing (instance {{ $labels.instance }})
              description: "A Prometheus target has disappeared. An exporter might be crashed.\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"
          - alert: PrometheusNotificationsBacklog
            expr: min_over_time(prometheus_notifications_queue_length[10m]) > 0
            for: 0m
            labels:
              severity: warning
            annotations:
              summary: Prometheus notifications backlog (instance {{ $labels.instance }})
              description: "The Prometheus notification queue has not been empty for 10 minutes\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"
          - alert: PrometheusTargetMissingWithWarmupTime
            expr: sum by (instance, job) ((up == 0) * on (instance) group_right(job) (node_time_seconds - node_boot_time_seconds > 600))
            for: 0m
            labels:
              severity: critical
            annotations:
              summary: Prometheus target missing with warmup time (instance {{ $labels.instance }})
              description: "Allow a job time to start up (10 minutes) before alerting that it's down.\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"
          - alert: PrometheusConfigurationReloadFailure
            expr: prometheus_config_last_reload_successful != 1
            for: 0m
            labels:
              severity: warning
            annotations:
              summary: Prometheus configuration reload failure (instance {{ $labels.instance }})
              description: "Prometheus configuration reload error\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"
          - alert: TraefikServiceDown
            expr: count(traefik_service_server_up) by (service) == 0
            for: 0m
            labels:
              severity: critical
            annotations:
              summary: Traefik service down (instance {{ $labels.instance }})
              description: "All Traefik services are down\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"
          - alert: JenkinsOffline
            expr: jenkins_node_offline_value > 1
            for: 0m
            labels:
              severity: critical
            annotations:
              summary: Jenkins offline (instance {{ $labels.instance }})
              description: "Jenkins offline: `{{$labels.instance}}` in realm {{$labels.realm}}/{{$labels.env}} ({{$labels.region}})\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"
          - alert: InstanceDown
            expr: up == 0
            for: 5m
            labels:
              severity: page
            annotations:
              description: "{{ $labels.instance }} of job {{ $labels.job }}/{{ $labels.kubernetes_pod_name }} has been down for more than 5 minutes."
              summary: "Instance {{ $labels.instance }} down"
          - alert: Pods Down
            expr: sum(kube_pod_status_phase{phase !~ "Running|Succeeded"}) by (phase) > 0
            for: 5m
            labels:
              severity: page
            annotations:
              description: "Bad pods for more than than 5 minutes."
              summary: "Instance {{ $labels.instance }} down"
          - alert: Unused PV
            expr: sum(kube_persistentvolume_status_phase{phase!~"Bound"}) by (phase) > 0
            for: 5m
            labels:
              severity: page
            annotations:
              description: "Unused pv for more than than 5 minutes."
              summary: "Unused PV"
          - alert: Broken PVC
            expr: sum(kube_persistentvolumeclaim_status_phase{phase!~"Bound"}) by (phase) > 0
            for: 5m
            labels:
              severity: page
            annotations:
              summary: "Broken PVC(s)"
          - alert: Matrix Bridge is down
            expr: bridge_connected == 0
            for: 5m
            labels:
              severity: page
            annotations:
              summary: "Matrix bridge is down"
